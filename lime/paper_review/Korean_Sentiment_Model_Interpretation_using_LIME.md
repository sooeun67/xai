# [논문 리뷰] [한국어 감성 분류 모델에 LIME 적용](https://doi.org/10.6109/jkiice.2021.25.12.1784) 

# 0. Summary
- **GOAL**: LIME 알고리즘을 이용하여 한국어 감성 분류 데이터셋으로 학습된 모델들의 입력 문장 내 단어들 중 어떤 단어가 결과에 영향을 미쳤는지 해석하고자 한다
- **RESULT**: 85.23% 성능의 Bi-LSTM 모델은 25,283개의 긍/부정 단어를 포함했지만, 상대적으로 낮은 성능을 보인 84.20%의 Transformer 모델의 해석 결과, 26,447개의 긍/부정 단어가 포함되어 있었다
- **CONCLUSION**: 따라서 Bi-LSTM 보다 Transformer 모델이 신뢰할 수 있는 모델로 확인했다
 
# 1. INTRODUCTION
- 블랙박스 모델의 한계: 신경망 모델은 높은 정확도로 입력 문장이 긍/부정인지 결과 예측을 알려줄 수 있지만, 어떤 단어들로 인해 그 결과가 예측되었는지 해석하기는 현재 불가능하다
  - 긍/부정과 연관없는 단어들로 인해 결과를 예측하거나, 토큰들의 상대적인 빈도 차이로 인해 학습이 편파적으로 이루어져 잘못 예측하는 경우 등의 오류를 범할 수 있다
- 정확도 지표 기반의 학습된 신경망 모델의 맹목적인 사용보다는 입력 문장 내 단어들 중 어떤 단어 에 근거하였는지 모델을 해석하는 것이 필요하다

# 2. KOREAN SENTIMENT MODEL
## 2-1. Bi-LSTM
## 2-2. Transformer

# 3. LIME (for text)

텍스트 데이터는 테이블, 이미지 데이터와 다른 방식으로 변형이 이루어진다.
새로운 텍스트는 원래 텍스트에서 임의로 단어를 제거하여 만들어진다. 데이터셋은 각 단어에 대해 이진 변수로 표현되는데, 단어가 변수에 포함되면 1, 제거되면 0의 값을 지닌다.

- input : “이번 영화 화이팅” 이고 띄어쓰기 기준으로 문장을 나눈다면, "이번", "영화", "화이팅" 토큰들에 대해 해석 가능한 표현은 이진 벡터 {1,1,1} 이 되며, 샘플 데이터는 모두 0이 아닌 경우를 제외한 {0,0,1}, (0,1,1} 등과 같은 벡터로 아래와 같이 표현 가능하다.

|이번|영화|화이팅|결과 문장|
|:----:|:---:|:---:|:---:|
|0|0|1|화이팅|
|0|1|1|영화 화이팅|
|1|1|1|이번 영화 화이팅|

# 4. EXPERIMENT
## 4-1. 실험 소개
- 모델은 크게 RNN, CNN, Transformer 3가지 종류로 실험 진행
- 데이터셋
	- [네이버 감성 분류 데이터셋](https://github.com/e9t/nsmc)으로 학습
	- [한국어 감성 사전](https://github.com/park1200656/KnuSentiLex): 
		- n-gram으로 이루어진 어절과 축약어 등의 긍/부정 단어들 포함
		- LIME 알고리즘을 통해 추출된 단어들이 긍/부정 단어들로써 모델에 영향을 주었는지 확인하기 위해 활용

## 4-2. 학습 결과

### 4-2-1. 정확도
- RNN 모델이 CNN 이나 Transformer 보다 상대적으로 높은 성능을 보였다
- Bi-RNN with single layer 와 CNN 모델이 각각 85.23%, 83.71%로 가장 높은 성능과 가장 낮은 성능을 보였다

### 4-2-2. 한국어 적용 결과
- LIME 알고리즘을 적용하여 각 모델들의 예측 값에 영향을 미친 단어들이 한국어 감성 사전에 속한단어인지 확인한 결과이다
- 각 모델들로부터 샘플링 된 긍정 단어(Sampled Positive Word)와 부정 단어(Sampled Negative Word)들이 한국어 감성 사전 내에 포함되어 있는 긍정 단어(Positive Word), 부정 단어(Negative Word)에 얼마나 포함되어 있는지 개수로 나타낸다
- 정확도는 RNN 모델 이 Transformer 모델보다 더 높지만 긍/부정 단어들이 예측 결과에 크게 영향을 미치지는 못했음 확인했다

### 4-2-2. 형태소 분석 전처리 후 적용 결과
- 조사와 같은 중립 단어들과 형태학적 자질 중 문장의 긍정, 부정적인 성격에 영향을 미치는 명사, 대명사 등을 포함한 체언과 동사, 형용사 등 을 포함한 용언, 그 외 품사들에 대한 빈도를 측정
- 모델 중 문장의 긍/부정적인 성격에 영향을 주는 체언과 용언이 가장 많이 추출된 모델은 6층 Transformer 모델이며, 가장 낮은 모델은 1층 순환 신경망 모델이었다


## 4-3. 결론

- 모델의 "정확도"와 LIME 기반의 "해설력"은 비례하지 않는다
	- 정확도가 가장 높았던 RNN 모델이 아닌, Transformer 모델에 LIME을 적용할 때 확인되는 긍/부정 단어들이 더 많았다
- Transformer 모델이 다른 비교 모델들에 비해 학습 과정에서 문장의 긍/부정적인 성격을 가지게 만드는 단어들을 학습하여 결과 값을 예측한다고 볼 수 있다

