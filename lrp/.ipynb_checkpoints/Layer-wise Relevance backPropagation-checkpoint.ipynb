{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist  # 라이브러리가 기본으로 제공하는 mnist 데이터셋\n",
    "from tensorflow.keras.utils import to_categorical  # one-hot encoding 을 위한 함수\n",
    "from tensorflow.keras.models import Sequential  # 레이어를 층층히 쌓아가는 연쇄 모델\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import load_model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[shape] train: (50000, 28, 28) \n",
      "[shape] test: (10000, 28, 28) \n",
      "[shape] valid: (10000, 28, 28) \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fda901f67b8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train_, y_train_), (x_valid_, y_valid_) = mnist.load_data()\n",
    "x_test_, y_test_ = x_train_[50000:], y_train_[50000:]\n",
    "x_train_,y_train_ = x_train_[:50000], y_train_[:50000]\n",
    "\n",
    "print(f'[shape] train: {x_train_.shape} ')\n",
    "print(f'[shape] test: {x_test_.shape} ')\n",
    "print(f'[shape] valid: {x_valid_.shape} ')\n",
    "\n",
    "plt.imshow(x_train_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[shape] before train: (50000, 28, 28) \n",
      "[shape] after train: (50000, 784) \n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train_.shape[1]*x_train_.shape[2]\n",
    "class_num = len(set(y_train_))\n",
    "\n",
    "x_train = (x_train_/255.0).reshape(-1, input_shape)\n",
    "x_test = (x_test_/255.0).reshape(-1, input_shape)\n",
    "x_valid = (x_valid_/255.0).reshape(-1, input_shape)\n",
    "\n",
    "print(f'[shape] before train: {x_train_.shape} ')\n",
    "print(f'[shape] after train: {x_train.shape} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[example] before train: 0 \n",
      "[example] after train: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "I = np.eye(10)\n",
    "\n",
    "y_train = I[y_train_]\n",
    "y_test = I[y_test_]\n",
    "y_valid = I[y_valid_]\n",
    "\n",
    "print(f'[example] before train: {y_train_[1]} ')\n",
    "print(f'[example] after train: {y_train[1]} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = MNISTLoader()\n",
    "\t\t\n",
    "x_train, y_train = dataloader.train\n",
    "x_validation, y_validation = dataloader.validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Feed-forward network\n",
    "# -------------------------\n",
    "class Network:\n",
    "    def __init__(self,layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self,Z):\n",
    "        for l in self.layers: Z = l.forward(Z)\n",
    "        return Z\n",
    "    \n",
    "    def gradprop(self,DZ):\n",
    "        for l in self.layers[::-1]: DZ = l.gradprop(DZ)\n",
    "        return DZ\n",
    "    \n",
    "    def relprop(self, R):\n",
    "        for I in self.layers[::-1]: R = I.relprop(R)\n",
    "        return R\n",
    "\n",
    "# -------------------------\n",
    "# ReLU activation layer\n",
    "# -------------------------\n",
    "class ReLU:\n",
    "    def forward(self,X):\n",
    "        self.Z = X>0\n",
    "        return X*self.Z\n",
    "    \n",
    "    def gradprop(self,DY):\n",
    "        return DY*self.Z\n",
    "    \n",
    "    def relprop(self, R): \n",
    "        return R\n",
    "    \n",
    "# -------------------------\n",
    "# Fully-connected layer\n",
    "# -------------------------\n",
    "class Linear:\n",
    "\n",
    "    def __init__(self, weight, bias):\n",
    "        self.W = weight\n",
    "        self.B = bias\n",
    "\n",
    "    def forward(self,X):\n",
    "        self.X = X\n",
    "        return np.dot(self.X,self.W)+self.B\n",
    "\n",
    "    def gradprop(self,DY):\n",
    "        self.DY = DY # DY는 target을 넣으면 됨. Desired Y\n",
    "        return np.dot(self.DY,self.W.T)\n",
    "\n",
    "class NextLinear(Linear): # implementing Z+ rule\n",
    "    def relprop(self,R):\n",
    "        V = np.maximum(0,self.W) # V는 W_ij^+를 의미함.\n",
    "        Z = np.dot(self.X,V)+1e-9; S = R/Z\n",
    "        C = np.dot(S,V.T);         R = self.X*C\n",
    "        return R\n",
    "    \n",
    "class FirstLinear(Linear): # implementing Zbeta rule\n",
    "    def relprop(self,R):\n",
    "        W,V,U = self.W,np.maximum(0,self.W),np.minimum(0,self.W)\n",
    "#        X,L,H = self.X,self.X*0+utils.lowest,self.X*0+utils.highest\n",
    "        X,L,H = self.X,self.X*0+(-1),self.X*0+(1.0)\n",
    "\n",
    "\n",
    "        Z = np.dot(X,W)-np.dot(L,V)-np.dot(H,U)+1e-9; S = R/Z\n",
    "        R = X*np.dot(S,W.T)-L*np.dot(S,V.T)-H*np.dot(S,U.T)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_W1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a0950cc964e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Network 구조 입력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m nn = Network([\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mFirstLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_W1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_b1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mNextLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_W2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_b2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mNextLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_W3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_b3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_W1' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Feed-forward network\n",
    "# -------------------------\n",
    "class Network:\n",
    "    def __init__(self,layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self,Z):\n",
    "        for l in self.layers: Z = l.forward(Z)\n",
    "        return Z\n",
    "    \n",
    "    def gradprop(self,DZ):\n",
    "        for l in self.layers[::-1]: DZ = l.gradprop(DZ)\n",
    "        return DZ\n",
    "    \n",
    "    def relprop(self, R):\n",
    "        for I in self.layers[::-1]: R = I.relprop(R)\n",
    "        return R\n",
    "\n",
    "# -------------------------\n",
    "# ReLU activation layer\n",
    "# -------------------------\n",
    "class ReLU:\n",
    "    def forward(self,X):\n",
    "        self.Z = X>0\n",
    "        return X*self.Z\n",
    "    \n",
    "    def gradprop(self,DY):\n",
    "        return DY*self.Z\n",
    "    \n",
    "    def relprop(self, R): \n",
    "        return R\n",
    "    \n",
    "# -------------------------\n",
    "# Fully-connected layer\n",
    "# -------------------------\n",
    "class Linear:\n",
    "\n",
    "  def __init__(self, weight, bias):\n",
    "    self.W = weight\n",
    "    self.B = bias\n",
    "\n",
    "  def forward(self,X):\n",
    "    self.X = X\n",
    "    return np.dot(self.X,self.W)+self.B\n",
    "\n",
    "  def gradprop(self,DY):\n",
    "    self.DY = DY # DY는 target을 넣으면 됨. Desired Y\n",
    "    return np.dot(self.DY,self.W.T)\n",
    "\n",
    "\n",
    "class NextLinear(Linear): # implementing Z+ rule\n",
    "    def relprop(self,R):\n",
    "        V = np.maximum(0,self.W) # V는 W_ij^+를 의미함.\n",
    "        Z = np.dot(self.X,V)+1e-9; S = R/Z\n",
    "        C = np.dot(S,V.T);         R = self.X*C\n",
    "        return R\n",
    "    \n",
    "class FirstLinear(Linear): # implementing Zbeta rule\n",
    "    def relprop(self,R):\n",
    "        W,V,U = self.W,np.maximum(0,self.W),np.minimum(0,self.W)\n",
    "#        X,L,H = self.X,self.X*0+utils.lowest,self.X*0+utils.highest\n",
    "        X,L,H = self.X,self.X*0+(-1),self.X*0+(1.0)\n",
    "\n",
    "\n",
    "        Z = np.dot(X,W)-np.dot(L,V)-np.dot(H,U)+1e-9; S = R/Z\n",
    "        R = X*np.dot(S,W.T)-L*np.dot(S,V.T)-H*np.dot(S,U.T)\n",
    "        return R\n",
    "\n",
    "# Network 구조 입력\n",
    "nn = Network([\n",
    "    FirstLinear(final_W1, final_b1),ReLU(),\n",
    "    NextLinear(final_W2, final_b2),ReLU(),\n",
    "    NextLinear(final_W3, final_b3),ReLU(),\n",
    "    NextLinear(final_W4, final_b4),ReLU(),\n",
    "    NextLinear(final_Wh, final_bh),ReLU(),\n",
    "])\n",
    "\n",
    "rand_num = np.random.permutation(n_total)\n",
    "\n",
    "X = total_x[rand_num,:] # Input\n",
    "T = total_y[rand_num,:] # Target\n",
    "Y = nn.forward(X) # Output\n",
    "S = nn.gradprop(T)**2\n",
    "Y = nn.forward(X)\n",
    "\n",
    "D = nn.relprop(Y*T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_dense(activation, kernel, bias, relevance):\n",
    "    W_p = tf.maximum(0., kernel)\n",
    "    b_p = tf.maximum(0., bias)\n",
    "    z_p = tf.matmul(activation, W_p) + b_p\n",
    "    s_p = relevance / z_p\n",
    "    c_p = tf.matmul(s_p, tf.transpose(W_p))\n",
    "\n",
    "    W_n = tf.minimum(0., kernel)\n",
    "    b_n = tf.minimum(0., bias)\n",
    "    z_n = tf.matmul(activation, W_n) + b_n\n",
    "    s_n = relevance / z_n\n",
    "    c_n = tf.matmul(s_n, tf.transpose(W_n))\n",
    "\n",
    "    return activation * (self.alpha * c_p + (1 - self.alpha) * c_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MNIST_DNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ae5d332abc86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Initialize neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mDNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST_DNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DNN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Setup training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MNIST_DNN' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('Classifier'):\n",
    "\n",
    "    # Initialize neural network\n",
    "    DNN = MNIST_DNN('DNN')\n",
    "\n",
    "    # Setup training process\n",
    "    X = tf.placeholder(tf.float32, [None, 784], name='X')\n",
    "    Y = tf.placeholder(tf.float32, [None, 10], name='Y')\n",
    "\n",
    "    activations, logits = DNN(X)\n",
    "    \n",
    "    tf.add_to_collection('LRP', X)\n",
    "    \n",
    "    for activation in activations:\n",
    "        tf.add_to_collection('LRP', activation)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost, var_list=DNN.vars)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "cost_summary = tf.summary.scalar('Cost', cost)\n",
    "accuray_summary = tf.summary.scalar('Accuracy', accuracy)\n",
    "summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "# Hyper parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    avg_acc = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c, a, summary_str = sess.run([optimizer, cost, accuracy, summary], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        avg_cost += c / total_batch\n",
    "        avg_acc += a / total_batch\n",
    "        \n",
    "        file_writer.add_summary(summary_str, epoch * total_batch + i)\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), 'accuracy =', '{:.9f}'.format(avg_acc))\n",
    "    \n",
    "    saver.save(sess, ckptdir)\n",
    "\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_CNN:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, X, reuse=False):\n",
    "\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            with tf.variable_scope('layer0'):\n",
    "                X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "            # Convolutional Layer #1 and Pooling Layer #1\n",
    "            with tf.variable_scope('layer1'):\n",
    "                conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu, use_bias=False)\n",
    "                pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], padding=\"SAME\", strides=2)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            with tf.variable_scope('layer2'):\n",
    "                conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu, use_bias=False)\n",
    "                pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], padding=\"SAME\", strides=2)\n",
    "\n",
    "            # Convolutional Layer #3 and Pooling Layer #3\n",
    "            with tf.variable_scope('layer3'):\n",
    "                conv3 = tf.layers.conv2d(inputs=pool2, filters=128, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu, use_bias=False)\n",
    "                pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], padding=\"SAME\", strides=2)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            with tf.variable_scope('layer4'):\n",
    "                flat = tf.reshape(pool3, [-1, 128 * 4 * 4])\n",
    "                dense4 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu, use_bias=False)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            with tf.variable_scope('layer5'):\n",
    "                logits = tf.layers.dense(inputs=dense4, units=10, use_bias=False)\n",
    "                prediction = tf.nn.softmax(logits)\n",
    "\n",
    "        return [X_img, conv1, pool1, conv2, pool2, conv3, pool3, flat, dense4, prediction], logits\n",
    "\n",
    "    @property\n",
    "    def vars(self):\n",
    "        return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
