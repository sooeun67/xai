# Explainable Artificial Intelligence [XAI]
<b>XAI</b> - "ì„¤ëª… ê°€ëŠ¥í•œ ì¸ê³µì§€ëŠ¥"
> - 1975ë…„, 'ì„¤ëª… ê°€ëŠ¥í•œ ì˜ì‚¬ ê²°ì • ì²´ê³„'ì˜ ìš©ì–´ ë“±ì¥, Shortliffe. Edward H., and Bruce G. Buchanan . "A model of inexact reasoning in medicine." Mathematical biosciences 23.3-4(1975)
> - 2004ë…„, "XA"I ìš©ì–´ ë“±ì¥, Michel van Lent, Willian Fisher and Michael Mancuso. "An explainable artificial intelligence system for small-unit tactical behavior.", Proceedings of the National Conference on Artificial Intelligence. Menlo Park, 2004 
> - 2016ë…„, DARPA (Depense Advanced Research Projects Agency), Project BAA-16-53, Explainable Artificial Intelligence, XAI. (~Y21) : ì°¸ì¡° https://ojs.aaai.org/index.php/aimagazine/article/view/2850
> <img src="xai_intro/images/darpa_intro2.png" alt="drawing" style="width:600px;"/>

Accuracy ì™€ Explainability ì˜ Trade-Off ê´€ê³„ì— ë”°ë¼ ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ë¶„ì„ê°€ë“¤ì´ ì ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•œ ê³ ë¯¼ì´ ê¹Šì–´ì§
DL ì „ìš©ë°©ë²•ë¡ , ì–´ë– í•œ ëª¨ë¸ì´ë“  í›ˆë ¨ëœ ëª¨ë¸ ìì²´ë¥¼ í•´ì„í•˜ëŠ” ê¸°ë²• ê·¸ë¦¬ê³  ì–´ë– í•œ ëª¨ë¸ì´ë“  í›ˆë ¨ëœ ëª¨ë¸ì˜ ëŒ€ì•ˆëª¨ë¸ì„ í†µí•´ í•´ì„í•˜ëŠ” ê¸°ë²• ì¤‘ì‹¬ìœ¼ë¡œ ë°œì „í•˜ê³  ìˆìŒ.
> <img src="xai_intro/images/darpa_intro.png" alt="drawing" style="width:600px;"/>

í˜„ì¬ State of The Art (SOTA)ë¡œ í‰ê°€ë˜ëŠ” ê²ƒì€ SHAPë¡œ ë³´ì´ë©° ê°ì¢… platformì— ì´ ê¸°ë²•ì´ ì¥ì°©ë˜ê³  ìˆëŠ” ì¶”ì„¸.
ì•„ë˜ëŠ” MS-AZURE ê²½ìš°ì´ë©° ì´ ì™¸ Python-Orange3 ì˜ plug-in ìœ¼ë¡œ SHAP, Explain ì´ ì´ë¯¸ ì œì‘ë˜ì–´ ìˆìŒ.
> <img src="xai_intro/images/Azure_shap.png" alt="drawing" style="width:600px;"/>

## Interpretability/explainability
- Explainability: possibility to explain from a technical point of view the prediction of an algorithm.
- Interpretability: the ability to explain or provide meaning in terms that are understandable by a human being.
- Transparency: a model is considered transparent if it is understandable on its own.

``` 
- Interpretability is the degree to which a human can understand the cause of a decision. 
- Another one is: Interpretability is the degree to which a human can consistently predict the modelâ€™s result.  
- The higher the interpretability of a machine learning model, the easier it is for someone to comprehend why certain decisions or predictions have been made.  
- A model is better interpretable than another model if its decisions are easier for a human to comprehend than decisions from the other model.   
- Christoph Molnar use the terms interpretable and explainable interchangeably like Miller (2017) But "Explanation" was used for explanations of individual predictions
- https://christophm.github.io/interpretable-ml-book/interpretability.html
```

---

## Model Specific Interpretation VS. Model Agnostic Interpretation
ê¸°ì¡´ ëª¨ë¸ìì²´ë¥¼ í•´ì„í•˜ë ¤ëŠ” ë°©ë²•, ê·¸ë¦¬ê³  ì´ì œ XAI ê¸°ë²•ì„ í†µí•œ ë²”ìš©ëª¨ë¸ í•´ì„ë°©ë²•ì„ ê³ ì°°í•´ë³´ì

### Accuracy VS. Explainablity
Trade-Off : To maximize performance, we use high-capability model. But it is hard to explain the result

- ë°ì´í„°ì˜ ë³µì¡ë„ê°€ ë†’ì•„ì§€ë©° Capacityê°€ ë†’ì€ ëª¨ë¸ì´ ì„±ëŠ¥ì´ ì¢‹ìŒ. ê·¸ëŸ¬ë‚˜ ì„¤ëª…í•˜ê¸°ëŠ” ë”ìš± í˜ë“¤ì–´ì§.
- ì„¤ëª…ì„ ìœ„í•´ Capacityê°€ ë‚®ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë³µì¡í•œ ë°ì´í„°ì— ëŒ€í•œ ì„±ëŠ¥ì´ ì €í•˜ë˜ì–´ ì‹¤ì ìš©íˆ í˜ë“¦ì–´ì§.
- Linear/Logistic Regression, Decision Tree, kNN ë“±ì´ ëŒ€í‘œì ì¸ ì„¤ëª…ì´ ìƒëŒ€ì ìœ¼ë¡œ ìš©ì´í•˜ë‚˜ ë³µì¡í•œ ë°ì´í„°ì— ëŒ€í•´ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” Model Specific Interpretation ì˜ì—­ì— ì†í•¨

> <img src="xai_intro/images/interpretability_Acc.png" alt="drawing" style="width:600px;"/>


---

### Model Specific Interpretation
> <img src="xai_intro/images/model_specific.png" alt="drawing" style="width:600px;"/>

#### Linear Regression (ì´ë¡ ì ìœ¼ë¡œ í•´ì„ì´ ê°€ëŠ¥)
- ìƒê´€ê³„ìˆ˜(ğ›½)ë¥¼ â€˜í•´ì„ë ¥â€™ì§€í‘œë¡œì„œ ê°„ë‹¨íˆ ì°¸ê³ ê°€ëŠ¥
- t-statistic ë“± ê³ ì „í†µê³„ê¸°ë²•ìœ¼ë¡œ ğ›½ì˜ ìœ ì˜ì„± ê²€ì¦ ê°€ëŠ¥
- ë…ë¦½ë³€ìˆ˜ì¸ ê²½ìš° ì¸ìë³„ ë¯¼ê°ë„ (í¬ê¸° ë° (Â±)) íš¨ê³¼ ë° ì¢…í•© íš¨ê³¼ë¥¼ íŒŒì•… ê°€ëŠ¥
- ë¹„ì„ í˜•ê´€ê³„ íŒŒì•…ì„ ìœ„í•´ì„œëŠ” x ì— ëŒ€í•œ ì¡°ì‘ì´ í•„ìš” 
  - ë…ë¦½ë³€ìˆ˜í™” (ë³€ìˆ˜ì˜ ì§êµí™”, PCA ë“±)
  - Feature Engineering (ì„ í˜•í™” ë“±)

#### Decision Tree (ì„¤ëª…ì´ê°€ëŠ¥)
- ëª¨ë¸ì˜ ì˜ì‚¬ê²°ì • ê³¼ì •ì„ ìì—°ìŠ¤ëŸ½ê²Œ íŒŒì•… ê°€ëŠ¥
- ë³€ìˆ˜ì˜ criteriaì— ë”°ë¼ ì–´ë– í•œ ê²°ê³¼ì— ë„ë‹¬í•˜ëŠ”ì§€ ì§ê´€ì ìœ¼ë¡œ íŒŒì•…
- ì–´ë– í•œ ë³€ìˆ˜ê°€ ì§€ì†ì ìœ¼ë¡œ ì¤‘ìš”ë³€ìˆ˜ì¸ì§€ ì§ê´€ì ì¸ íŒŒì•…

#### Tree Ensemble Models (í•´ì„ì€ ê°€ëŠ¥í•˜ë‚˜ ì–´ë ¤ì›€)
- Random forest, Gradient Boosting tree
- ì•ì„  ë‘ ë°©ë²•ë³´ë‹¤ ë³µì¡í•œ ë°ì´í„°ì— ëŒ€í•´ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ëƒ„
- Tree ë¶„ê¸° ì‹œ í•´ë‹¹ ë³€ìˆ˜ì˜ í‰ê· ì ì¸ ë¶ˆìˆœë„ ê°ì†ŒëŸ‰ì„ í†µí•´ ë³€ìˆ˜ì¤‘ìš”ë„ë¡œ íŒŒì•…
- ë‚´ë¶€ Tree ë³„ Decision Tree Stuctureë¥¼ í™œìš©í•œ ì„¤ëª…ë°©ë²•ì´ ì¡´ì¬í•˜ë‚˜ Treeë³„ë¡œ ë³´ê¸° í˜ë“  ë¶€ë¶„ì´ ì¡´ì¬


#### ëŒ€í‘œì ì¸ í•´ì„ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ì˜ ì•„ì‰¬ìš´ ì 
- ëª¨ë¸ë³„ í•´ì„ë°©ë²•ì´ í•´ë‹¹ ëª¨ë¸ì— ì¢…ì†ë˜ì–´ ìˆê¸°ì—, ë‹¤ë¥¸ ëª¨ë¸ê°„ ë¹„êµê°€ ì–´ë ¤ì›€
- ì„¤ëª…í•˜ê¸° ì‰¬ìš´ ëª¨ë¸ì¼ìˆ˜ë¡ ì„±ëŠ¥ì´ ì•„ì‰¬ìš´ ê²½ìš°ê°€ ë§ìŒ. (ì„±ëŠ¥ ì¤‘ì‹¬ì¸ ê²½ìš° ì„¤ëª…ì´ ì–´ë ¤ì›€)

---

## Model Agnostic Interpretation
- ì›ë˜ ëª¨ë¸ì„ Black-box ëª¨ë¸ë¡œ ë³¸ë‹¤
  - White-box ëª¨ë¸ì—ì„œ í–‰í•˜ë˜ ë°©ì‹ì²˜ëŸ¼ ëª¨ë¸ ë‚´ë¶€ ë³€ìˆ˜ ë° ê³„ìˆ˜ì— ì ‘ê·¼í•˜ì§€ ì•ŠìŒ. (Model Specific - Linear ëª¨ë¸ì˜ Beta ê³„ìˆ˜ ë° ìƒê´€ê´€ê³„ í•´ì„í•˜ì§€ ì•ŠìŒ)
  - ëª¨ë¸ì˜ inputì„ ì¡°ì ˆí•˜ë©° outputì„ ê³ ì°°, output ì´ë‚˜ ì›ë˜ê°’ê³¼ì˜ ì°¨ì´ ë³€ë™ì— ëŒ€í•´ì„œ í•´ì„
> <img src="xai_intro/images/model_agnostic.png" alt="drawing" style="width:600px;"/>


#### Deep Neural Network (ê¸°ì¡´ì˜ ë°©ë²•ìœ¼ë¡œ í•´ì„ ë¶ˆê°€ëŠ¥)
- ì‚¬ì‹¤ìƒ Black-box ëª¨ë¸ì´ë©° í•´ì„í•˜ê¸° ì–´ë ¤ìš´ ëª¨ë¸! 
- Attention, Class-Activation-Map ë“± ì¶”ê°€ì ì¸ êµ¬ì¡°ë¥¼ í†µí•œ í•´ì„ì´ ê°€ëŠ¥
  - ë‹¨, ì¶”ê°€ì ì¸ ëª¨ë¸ êµ¬ì¡° ë³€ê²½ì´ í•„ìš”


#### ë³µí•©ëª¨ë¸ Ensemble ë° Stacking (ê¸°ì¡´ì˜ ë°©ë²•ìœ¼ë¡œ í•´ì„ ë¶ˆê°€ëŠ¥)
- Ensemble ì— ì‚¬ìš©ë˜ëŠ” ë‹¨ì¼ ì•Œê³ ë¦¬ì¦˜ ìì²´ê°€ D/L, XGB ë“±ì˜ í•´ì„ì´ í˜ë“¤ê±°ë‚˜ ë¶ˆê°€ëŠ¥í•œ ëª¨ë¸ë“¤ë¡œ êµ¬ì„±ë˜ì–´ í•´ì„ì´ ê±°ì˜ ë¶ˆê°€ëŠ¥í•¨! 

---

## Model-Agnostic Methods
í•˜ê¸° ê¸°ìˆ ë“¤ê³¼ ìš©ì–´ë“¤ì„ ì •ë¦¬í•˜ë©´ ì•„ë˜ í‘œì™€ ê°™ìŒ. ìƒì„¸ë¶€ë¶„ì€ ê° ê¸°ìˆ ë“¤ì˜ Link ì°¸ì¡°
- Permutation Feature Importance (PFI)
- Partial Dependence Plot (PDP) and Individual Conditional Expectation (ICE)
- Local Interpretable Model-agnostic Explanations (LIME)
- SHAP (Shapley Additive explanations)
- FV and LRP (Filter Visualization and Layer Relevance Propagation)

```
- Agnostic : ëª¨ë“  ëª¨ë¸ì— ì ìš©ë˜ëŠ” ~
- Surrogate : ëª¨ë“  ëª¨ë¸ì— ì ìš©ë  ìˆ˜ ìˆë„ë¡ ëŒ€ì•ˆëª¨ë¸ì„ ë§Œë“¤ì–´ í•´ì„í•˜ëŠ” ~
- Local : ë‹¨ì¼ instance (ê°œë³„ ë°ì´í„°) ì— ëŒ€í•´ ì„¤ëª…ê°€ëŠ¥í•œ ~
- Global : ëª¨ë“  instance ì— ëŒ€í•´ ì¢…í•© ì„¤ëª…ê°€ëŠ¥í•œ ~
```
| Tech.Name | Model Dependency | Global/Local | NoteBook Example |
| :---         |     :---:      |          :---: |     :---:      |
| Feature Importance (FI)   | Specific     | Global    | [Example](pdp/notebook_exam/01_titanic/XAI_Example.html) |
| [Permutation FI (PFI)](pfi/01.Permutation_FI.md)  | Agnostic     | Global    | [Example](pdp/notebook_exam/01_titanic/XAI_Example.html) |
| [Partial Dependent Plot (PDP)](pdp/02.PDP_ICE.md)   | Agnostic     | Global    | [Example](pdp/notebook_exam/01_titanic/XAI_Example.html) |
| [Individual Conditional Expectation (ICE)](pdp/02.PDP_ICE.md)      | Agnostic       | Local     |  [Example](pdp/notebook_exam/01_titanic/XAI_Example.html) |
| [SHapley Additive exPlanations (SHAP)](shap/shap.md)     | Agnostic       | Local/Global      | [Example-Titanic](pdp/notebook_exam/01_titanic/XAI_Example.html)[Example-MNIST](https://github.com/sooeun67/xai/blob/main/shap/PyTorch_SHAP.ipynb) |
| [Local Interpretable Model Explanations (LIME)](lime/lime.md)     | Agnostic-Surrogate       | Local      | [Titanic Example](lime/titanic/titanic_lime.ipynb) / [MNIST example](lime/mnist/LIME_with_MNIST.ipynb)
| Layer-wise Relevance Propagation (LRP)     | DL Agnostic     | Local      | [MNIST example](lrp/LRP_mnist.ipynb)

[Example](pdp/notebook_exam/01_titanic/XAI_Example.ipynb)

---
## ì°¸ê³  
- [ì„œì ] XAI ì„¤ëª…ê°€ëŠ¥í•œ ì¸ê³µì§€ëŠ¥, ì¸ê³µì§€ëŠ¥ì„ í•´ë¶€í•˜ë‹¤, ì•ˆì¬í˜„, ìœ„í‚¤ë³µìŠ¤, 2020
- [ì„œì /WEB] Explainable AI ê¸°ë²•ì— ëŒ€í•œ Global/Local Review <https://christophm.github.io/interpretable-ml-book/>
- [WEB] ì „ë°˜ì ì¸ AI ê¸°ë²•ì— ëŒ€í•œ ì´ë¡ ì  ì„¤ëª… - dmqa.korea.ac.kr
- [WEB] PDP/ICE - https://scikit-learn.org/stable/modules/partial_dependence.html#
- [WEB] LIME https://github.com/marcotcr/lime
- [WEB] SHAP https://github.com/slundberg/shap
- [WEB] States of the ART tech. [https://paperswithcode.com/sota]
- [WEB] XAI ì„¤ëª… ë° ìµœê·¼ë™í–¥ https://medium.com/swlh/push-the-limits-of-explainability-an-ultimate-guide-to-shap-library-a110af566a02
- [Journal] Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI,  Arrieta, 2019 https://arxiv.org/pdf/1910.10045.pdf


